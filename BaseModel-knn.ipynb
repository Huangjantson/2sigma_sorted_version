{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "data_path = '/data/kaggleData/2sigma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KN\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 132)\n",
      "(74659, 131)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json(data_path + 'normalized_train.json')\n",
    "test_df = pd.read_json(data_path + 'normalized_test.json')\n",
    "print train_df.shape\n",
    "print test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing features for the KNN method, in order to speed up the algorithm and avoid overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statistical = []\n",
    "\n",
    "for feature in test_df.columns:\n",
    "    if re.match('((manager_id)|(house_type))\\S+((mean)|(median)|(min)|(max))',feature) !=None:\n",
    "        statistical.append(feature)\n",
    "        \n",
    "weightFeatures=[i for i in test_df.columns if i not in statistical ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weightFeatures.remove('another_day')\n",
    "weightFeatures.remove('another_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49352"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the weight for each feature by applyng logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.588708123194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=StratifiedKFold(train_y,5,shuffle=True,random_state = 2333)\n",
    "\n",
    "#run the logistic algorithm to do \n",
    "#numericals from xgb142 + some new hcc encoding + with_feat from xgb142\n",
    "cv_scores=[]\n",
    "models =[]\n",
    "for dev_index, val_index in KF:\n",
    "    dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "    dev_X, val_X = dev_set[weightFeatures].as_matrix(), val_set[weightFeatures].as_matrix()\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    #random forest us\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(dev_X,dev_y)\n",
    "    preds = lr.predict_proba(val_X)\n",
    "    models.append(lr)   \n",
    "    cv_scores.append(log_loss(val_y, preds))\n",
    "        \n",
    "\n",
    "    #print(cv_scores)\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coff = np.abs(models[0].coef_) \n",
    "for i in [1,2,3,4]:\n",
    "    coff+=np.abs(models[i].coef_) \n",
    "coeff = coff.sum(axis=0)\n",
    "\n",
    "total_weight={}\n",
    "total_weight_list=[]\n",
    "for i in range(len(weightFeatures)):\n",
    "    total_weight[weightFeatures[i]]=coeff[i]\n",
    "    total_weight_list.append((weightFeatures[i],coeff[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting the feature weight \n",
    "#trying knn using the weight from the above regression\n",
    "knn_train_df = train_df.copy()\n",
    "knn_test_df = test_df.copy()\n",
    "\n",
    "for feature_value in total_weight_list:\n",
    "    knn_train_df[feature_value[0]]*=np.sqrt(feature_value[1])\n",
    "    knn_test_df[feature_value[0]]*=np.sqrt(feature_value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = knn_train_df\n",
    "test_df = knn_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cv style generating output for training the meta classifier and generateing the output as meta feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=StratifiedKFold(train_y,5,shuffle=True,random_state = 2333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(weightFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for the turn 1 is 3.73216428793\n",
      "loss for the turn 2 is 3.51690516441\n",
      "loss for the turn 3 is 3.65620188683\n",
      "loss for the turn 4 is 3.73433829876\n",
      "loss for the turn 5 is 3.57432523277\n",
      "The mean of the cv_scores is:\n",
      "3.64278697414\n"
     ]
    }
   ],
   "source": [
    "#4 neighbor, cv-style for meta classifier training\n",
    "store = data_path+\"knn4/\"\n",
    "\n",
    "cv_scores=[]\n",
    "i=0\n",
    "\n",
    "for dev_index, val_index in KF: \n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "       #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    kn = KN(4)\n",
    "    kn.fit(dev_X,dev_y)\n",
    "    preds = kn.predict_proba(val_X)\n",
    "\n",
    "    #save the pickles for futures use\n",
    "    pickl_file = store+'knn4-5fold-out-'+str(i)+'.pickle'\n",
    "    fileObject = open(pickl_file,'wb') \n",
    "    pickle.dump(preds,fileObject)   \n",
    "    fileObject.close()\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    i+=1\n",
    "    print'loss for the turn '+str(i)+' is '+str(loss)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# running for meta feature\n",
    "train_X, test_X = train_df[features].as_matrix(), test_df[features].as_matrix()\n",
    "\n",
    "et = KN(4)\n",
    "et.fit(train_X,train_y)\n",
    "preds = et.predict_proba(test_X)\n",
    "\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_json(store+'kn4-bulk-out.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for the turn 1 is 1.90333706761\n",
      "loss for the turn 2 is 1.83688495811\n",
      "loss for the turn 3 is 1.87196682533\n",
      "loss for the turn 4 is 1.92746471344\n",
      "loss for the turn 5 is 1.91779881511\n",
      "The mean of the cv_scores is:\n",
      "1.89149047592\n"
     ]
    }
   ],
   "source": [
    "#8 neighbor, cv-style for meta classifier training\n",
    "store = data_path+\"knn8/\"\n",
    "\n",
    "cv_scores=[]\n",
    "i=0\n",
    "\n",
    "for dev_index, val_index in KF: \n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "       #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    kn = KN(8)\n",
    "    kn.fit(dev_X,dev_y)\n",
    "    preds = kn.predict_proba(val_X)\n",
    "\n",
    "    #save the pickles for futures use\n",
    "    pickl_file = store+'knn8-5fold-out-'+str(i)+'.pickle'\n",
    "    fileObject = open(pickl_file,'wb') \n",
    "    pickle.dump(preds,fileObject)   \n",
    "    fileObject.close()\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    i+=1\n",
    "    print'loss for the turn '+str(i)+' is '+str(loss)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# running for meta feature\n",
    "train_X, test_X = train_df[features].as_matrix(), test_df[features].as_matrix()\n",
    "\n",
    "et = KN(8)\n",
    "et.fit(train_X,train_y)\n",
    "preds = et.predict_proba(test_X)\n",
    "\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_json(store+'kn8-bulk-out.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for the turn 1 is 1.13724884705\n",
      "loss for the turn 2 is 1.070207089\n",
      "loss for the turn 3 is 1.07347600908\n",
      "loss for the turn 4 is 1.17321972508\n",
      "loss for the turn 5 is 1.12752517133\n",
      "The mean of the cv_scores is:\n",
      "1.11633536831\n"
     ]
    }
   ],
   "source": [
    "#16 neighbor, cv-style for meta classifier training\n",
    "store = data_path+\"knn16/\"\n",
    "\n",
    "cv_scores=[]\n",
    "i=0\n",
    "\n",
    "for dev_index, val_index in KF: \n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "       #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    kn = KN(16)\n",
    "    kn.fit(dev_X,dev_y)\n",
    "    preds = kn.predict_proba(val_X)\n",
    "\n",
    "    #save the pickles for futures use\n",
    "    pickl_file = store+'knn16-5fold-out-'+str(i)+'.pickle'\n",
    "    fileObject = open(pickl_file,'wb') \n",
    "    pickle.dump(preds,fileObject)   \n",
    "    fileObject.close()\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    i+=1\n",
    "    print'loss for the turn '+str(i)+' is '+str(loss)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# running for meta feature\n",
    "train_X, test_X = train_df[features].as_matrix(), test_df[features].as_matrix()\n",
    "\n",
    "et = KN(16)\n",
    "et.fit(train_X,train_y)\n",
    "preds = et.predict_proba(test_X)\n",
    "\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_json(store+'kn16-bulk-out.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for the turn 1 is 0.785093480922\n",
      "loss for the turn 2 is 0.76734245118\n",
      "loss for the turn 3 is 0.773748269132\n",
      "loss for the turn 4 is 0.826338507712\n",
      "loss for the turn 5 is 0.774227242632\n",
      "The mean of the cv_scores is:\n",
      "0.785349990316\n"
     ]
    }
   ],
   "source": [
    "#16 neighbor, cv-style for meta classifier training\n",
    "store = data_path+\"knn32/\"\n",
    "\n",
    "cv_scores=[]\n",
    "i=0\n",
    "\n",
    "for dev_index, val_index in KF: \n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "       #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    kn = KN(32)\n",
    "    kn.fit(dev_X,dev_y)\n",
    "    preds = kn.predict_proba(val_X)\n",
    "\n",
    "    #save the pickles for futures use\n",
    "    pickl_file = store+'knn32-5fold-out-'+str(i)+'.pickle'\n",
    "    fileObject = open(pickl_file,'wb') \n",
    "    pickle.dump(preds,fileObject)   \n",
    "    fileObject.close()\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    i+=1\n",
    "    print'loss for the turn '+str(i)+' is '+str(loss)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# running for meta feature\n",
    "train_X, test_X = train_df[features].as_matrix(), test_df[features].as_matrix()\n",
    "\n",
    "et = KN(32)\n",
    "et.fit(train_X,train_y)\n",
    "preds = et.predict_proba(test_X)\n",
    "\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_json(store+'kn32-bulk-out.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
