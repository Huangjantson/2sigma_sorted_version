{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import  preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold,StratifiedKFold\n",
    "import pickle\n",
    "from mochi import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 292)\n",
      "(74659, 291)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/data/kaggleData/2sigma/\"\n",
    "\n",
    "train_file = data_path + \"processed_train.json\"\n",
    "test_file = data_path + \"processed_test.json\"\n",
    "train_df = pd.read_json(train_file)\n",
    "test_df = pd.read_json(test_file)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dict = pd.read_pickle(data_path+'feature_set_dict.pkl')\n",
    "features = []\n",
    "for feature_set in feature_dict.keys():\n",
    "    features.extend(feature_dict[feature_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=StratifiedKFold(train_y,5,shuffle=True,random_state = 2333)\n",
    "\n",
    "train_df = train_df.fillna(-1)\n",
    "test_df = test_df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for the turn 3 is 0.586290364947\n",
      "loss for the turn 4 is 0.578498577962\n"
     ]
    }
   ],
   "source": [
    "store = data_path+'et1000mf140/'\n",
    "cv_scores=[]\n",
    "i=0\n",
    "\n",
    "for dev_index, val_index in KF: \n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "       #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    et = ETC(1000,random_state=0,max_features =140)\n",
    "    et.fit(dev_X,dev_y)\n",
    "    preds = et.predict_proba(val_X)\n",
    "\n",
    "    #save the pickles for futures use\n",
    "    pickl_file = store+'et1000mf140-5fold-out-'+str(i)+'.pickle'\n",
    "    fileObject = open(pickl_file,'wb') \n",
    "    pickle.dump(preds,fileObject)   \n",
    "    fileObject.close()\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    i+=1\n",
    "    print'loss for the turn '+str(i)+' is '+str(loss)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X = train_df[features].as_matrix(), test_df[features].as_matrix()\n",
    "\n",
    "et = ETC(1000,random_state=0,max_features =140)\n",
    "et.fit(train_X,train_y)\n",
    "preds = et.predict_proba(test_X)\n",
    "\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_json(store+'et1000mf140-bulk-out.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for the turn 1 is 0.568396878458\n"
     ]
    }
   ],
   "source": [
    "store = data_path+'rf1000mf70/'\n",
    "cv_scores=[]\n",
    "i=0\n",
    "\n",
    "for dev_index, val_index in KF: \n",
    "    result_dict = {}\n",
    "    \n",
    "    dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "       #filter the features\n",
    "    dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "    rf = RFC(1000,random_state=0,max_features =70)\n",
    "    rf.fit(dev_X,dev_y)\n",
    "    preds = rf.predict_proba(val_X)\n",
    "\n",
    "    #save the pickles for futures use\n",
    "    pickl_file = store+'rf1000mf70-5fold-out-'+str(i)+'.pickle'\n",
    "    fileObject = open(pickl_file,'wb') \n",
    "    pickle.dump(preds,fileObject)   \n",
    "    fileObject.close()\n",
    "\n",
    "    loss = log_loss(val_y, preds)\n",
    "    \n",
    "    cv_scores.append(loss)\n",
    "    i+=1\n",
    "    print'loss for the turn '+str(i)+' is '+str(loss)\n",
    "\n",
    "print 'The mean of the cv_scores is:'\n",
    "print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X = train_df[features].as_matrix(), test_df[features].as_matrix()\n",
    "\n",
    "rf = RFC(1000,random_state=0,max_features =70)\n",
    "rf.fit(train_X,train_y)\n",
    "preds = rf.predict_proba(test_X)\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df.to_json(store+'rf1000mf70-bulk-out.json')\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
