{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold,StratifiedKFold\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '/data/kaggleData/2sigma/'\n",
    "store = data_path+'nn/'\n",
    "\n",
    "train_df=pd.read_json(data_path+'normalized_train.json')\n",
    "test_df=pd.read_json(data_path+'normalized_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_model(features,num_classes=3,lr=0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,  \n",
    "                    activation='softplus',\n",
    "                    input_shape = (len(features),),\n",
    "                                  kernel_initializer='he_normal',\n",
    "                                  kernel_regularizer=l2(0.000025)\n",
    "                                  ))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(16,\n",
    "                    activation='softplus', \n",
    "                    kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(0.000025)\n",
    "                    ))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(units=num_classes, \n",
    "                    activation='softmax', \n",
    "                    kernel_initializer='he_normal',\n",
    "                    ))\n",
    "    opt = optimizers.Adadelta(lr=1)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy']\n",
    "                  )\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare for training\n",
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "\n",
    "train_y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))\n",
    "\n",
    "KF=StratifiedKFold(train_y,5,shuffle=True,random_state = 2333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "4s - loss: 0.7134 - acc: 0.6990\n",
      "Epoch 2/40\n",
      "4s - loss: 0.6346 - acc: 0.7194\n",
      "Epoch 3/40\n",
      "4s - loss: 0.6253 - acc: 0.7216\n",
      "Epoch 4/40\n",
      "4s - loss: 0.6189 - acc: 0.7250\n",
      "Epoch 5/40\n",
      "4s - loss: 0.6157 - acc: 0.7267\n",
      "Epoch 6/40\n",
      "4s - loss: 0.6124 - acc: 0.7277\n",
      "Epoch 7/40\n",
      "4s - loss: 0.6102 - acc: 0.7300\n",
      "Epoch 8/40\n",
      "4s - loss: 0.6081 - acc: 0.7293\n",
      "Epoch 9/40\n",
      "4s - loss: 0.6061 - acc: 0.7323\n",
      "Epoch 10/40\n",
      "4s - loss: 0.6015 - acc: 0.7329\n",
      "Epoch 11/40\n",
      "4s - loss: 0.6038 - acc: 0.7333\n",
      "Epoch 12/40\n",
      "4s - loss: 0.6005 - acc: 0.7349\n",
      "Epoch 13/40\n",
      "4s - loss: 0.5992 - acc: 0.7363\n",
      "Epoch 14/40\n",
      "4s - loss: 0.5978 - acc: 0.7350\n",
      "Epoch 15/40\n",
      "4s - loss: 0.5955 - acc: 0.7374\n",
      "Epoch 16/40\n",
      "4s - loss: 0.5955 - acc: 0.7375\n",
      "Epoch 17/40\n",
      "4s - loss: 0.5929 - acc: 0.7385\n",
      "Epoch 18/40\n",
      "4s - loss: 0.5922 - acc: 0.7379\n",
      "Epoch 19/40\n",
      "4s - loss: 0.5917 - acc: 0.7392\n",
      "Epoch 20/40\n",
      "5s - loss: 0.5912 - acc: 0.7379\n",
      "Epoch 21/40\n",
      "4s - loss: 0.5904 - acc: 0.7376\n",
      "Epoch 22/40\n",
      "4s - loss: 0.5888 - acc: 0.7405\n",
      "Epoch 23/40\n",
      "3s - loss: 0.5879 - acc: 0.7419\n",
      "Epoch 24/40\n",
      "4s - loss: 0.5869 - acc: 0.7411\n",
      "Epoch 25/40\n",
      "4s - loss: 0.5851 - acc: 0.7431\n",
      "Epoch 26/40\n",
      "4s - loss: 0.5848 - acc: 0.7424\n",
      "Epoch 27/40\n",
      "4s - loss: 0.5867 - acc: 0.7401\n",
      "Epoch 28/40\n",
      "4s - loss: 0.5850 - acc: 0.7421\n",
      "Epoch 29/40\n",
      "4s - loss: 0.5837 - acc: 0.7423\n",
      "Epoch 30/40\n",
      "3s - loss: 0.5828 - acc: 0.7417\n",
      "Epoch 31/40\n",
      "4s - loss: 0.5821 - acc: 0.7419\n",
      "Epoch 32/40\n",
      "4s - loss: 0.5813 - acc: 0.7430\n",
      "Epoch 33/40\n",
      "4s - loss: 0.5818 - acc: 0.7437\n",
      "Epoch 34/40\n",
      "4s - loss: 0.5806 - acc: 0.7430\n",
      "Epoch 35/40\n",
      "4s - loss: 0.5778 - acc: 0.7452\n",
      "Epoch 36/40\n",
      "4s - loss: 0.5784 - acc: 0.7430\n",
      "Epoch 37/40\n",
      "4s - loss: 0.5795 - acc: 0.7447\n",
      "Epoch 38/40\n",
      "4s - loss: 0.5785 - acc: 0.7431\n",
      "Epoch 39/40\n",
      "4s - loss: 0.5791 - acc: 0.7445\n",
      "Epoch 40/40\n",
      "4s - loss: 0.5776 - acc: 0.7452\n",
      "9760/9871 [============================>.] - ETA: 0s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 1 turn is:\n",
      "0.579498898645\n",
      "Epoch 1/40\n",
      "4s - loss: 0.7143 - acc: 0.6966\n",
      "Epoch 2/40\n",
      "4s - loss: 0.6394 - acc: 0.7158\n",
      "Epoch 3/40\n",
      "4s - loss: 0.6300 - acc: 0.7193\n",
      "Epoch 4/40\n",
      "4s - loss: 0.6222 - acc: 0.7196\n",
      "Epoch 5/40\n",
      "4s - loss: 0.6207 - acc: 0.7232\n",
      "Epoch 6/40\n",
      "4s - loss: 0.6171 - acc: 0.7257\n",
      "Epoch 7/40\n",
      "4s - loss: 0.6125 - acc: 0.7258\n",
      "Epoch 8/40\n",
      "5s - loss: 0.6116 - acc: 0.7283\n",
      "Epoch 9/40\n",
      "4s - loss: 0.6096 - acc: 0.7309\n",
      "Epoch 10/40\n",
      "4s - loss: 0.6064 - acc: 0.7310\n",
      "Epoch 11/40\n",
      "4s - loss: 0.6045 - acc: 0.7307\n",
      "Epoch 12/40\n",
      "5s - loss: 0.6047 - acc: 0.7321\n",
      "Epoch 13/40\n",
      "4s - loss: 0.6033 - acc: 0.7334\n",
      "Epoch 14/40\n",
      "4s - loss: 0.5996 - acc: 0.7363\n",
      "Epoch 15/40\n",
      "4s - loss: 0.5994 - acc: 0.7354\n",
      "Epoch 16/40\n",
      "4s - loss: 0.5999 - acc: 0.7363\n",
      "Epoch 17/40\n",
      "4s - loss: 0.5983 - acc: 0.7362\n",
      "Epoch 18/40\n",
      "4s - loss: 0.5978 - acc: 0.7371\n",
      "Epoch 19/40\n",
      "4s - loss: 0.5947 - acc: 0.7358\n",
      "Epoch 20/40\n",
      "4s - loss: 0.5945 - acc: 0.7364\n",
      "Epoch 21/40\n",
      "4s - loss: 0.5939 - acc: 0.7377\n",
      "Epoch 22/40\n",
      "4s - loss: 0.5930 - acc: 0.7379\n",
      "Epoch 23/40\n",
      "4s - loss: 0.5910 - acc: 0.7375\n",
      "Epoch 24/40\n",
      "3s - loss: 0.5910 - acc: 0.7382\n",
      "Epoch 25/40\n",
      "4s - loss: 0.5907 - acc: 0.7394\n",
      "Epoch 26/40\n",
      "4s - loss: 0.5892 - acc: 0.7388\n",
      "Epoch 27/40\n",
      "4s - loss: 0.5881 - acc: 0.7402\n",
      "Epoch 28/40\n",
      "4s - loss: 0.5878 - acc: 0.7393\n",
      "Epoch 29/40\n",
      "4s - loss: 0.5889 - acc: 0.7379\n",
      "Epoch 30/40\n",
      "4s - loss: 0.5871 - acc: 0.7411\n",
      "Epoch 31/40\n",
      "4s - loss: 0.5862 - acc: 0.7378\n",
      "Epoch 32/40\n",
      "4s - loss: 0.5849 - acc: 0.7423\n",
      "Epoch 33/40\n",
      "4s - loss: 0.5855 - acc: 0.7422\n",
      "Epoch 34/40\n",
      "5s - loss: 0.5844 - acc: 0.7404\n",
      "Epoch 35/40\n",
      "4s - loss: 0.5830 - acc: 0.7417\n",
      "Epoch 36/40\n",
      "4s - loss: 0.5833 - acc: 0.7429\n",
      "Epoch 37/40\n",
      "4s - loss: 0.5836 - acc: 0.7397\n",
      "Epoch 38/40\n",
      "3s - loss: 0.5816 - acc: 0.7422\n",
      "Epoch 39/40\n",
      "4s - loss: 0.5816 - acc: 0.7425\n",
      "Epoch 40/40\n",
      "4s - loss: 0.5809 - acc: 0.7416\n",
      "9536/9871 [===========================>..] - ETA: 0s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 2 turn is:\n",
      "0.56891235708\n",
      "Epoch 1/40\n",
      "5s - loss: 0.7082 - acc: 0.6997\n",
      "Epoch 2/40\n",
      "4s - loss: 0.6377 - acc: 0.7173\n",
      "Epoch 3/40\n",
      "4s - loss: 0.6259 - acc: 0.7231\n",
      "Epoch 4/40\n",
      "4s - loss: 0.6237 - acc: 0.7207\n",
      "Epoch 5/40\n",
      "4s - loss: 0.6178 - acc: 0.7235\n",
      "Epoch 6/40\n",
      "4s - loss: 0.6138 - acc: 0.7263\n",
      "Epoch 7/40\n",
      "4s - loss: 0.6107 - acc: 0.7288\n",
      "Epoch 8/40\n",
      "4s - loss: 0.6101 - acc: 0.7294\n",
      "Epoch 9/40\n",
      "4s - loss: 0.6078 - acc: 0.7298\n",
      "Epoch 10/40\n",
      "4s - loss: 0.6050 - acc: 0.7335\n",
      "Epoch 11/40\n",
      "4s - loss: 0.6052 - acc: 0.7333\n",
      "Epoch 12/40\n",
      "4s - loss: 0.6036 - acc: 0.7332\n",
      "Epoch 13/40\n",
      "5s - loss: 0.6018 - acc: 0.7345\n",
      "Epoch 14/40\n",
      "4s - loss: 0.5994 - acc: 0.7343\n",
      "Epoch 15/40\n",
      "5s - loss: 0.5974 - acc: 0.7342\n",
      "Epoch 16/40\n",
      "4s - loss: 0.5976 - acc: 0.7352\n",
      "Epoch 17/40\n",
      "5s - loss: 0.5949 - acc: 0.7370\n",
      "Epoch 18/40\n",
      "4s - loss: 0.5951 - acc: 0.7366\n",
      "Epoch 19/40\n",
      "4s - loss: 0.5939 - acc: 0.7374\n",
      "Epoch 20/40\n",
      "4s - loss: 0.5939 - acc: 0.7377\n",
      "Epoch 21/40\n",
      "4s - loss: 0.5907 - acc: 0.7392\n",
      "Epoch 22/40\n",
      "5s - loss: 0.5910 - acc: 0.7375\n",
      "Epoch 23/40\n",
      "4s - loss: 0.5900 - acc: 0.7369\n",
      "Epoch 24/40\n",
      "4s - loss: 0.5899 - acc: 0.7392\n",
      "Epoch 25/40\n",
      "4s - loss: 0.5884 - acc: 0.7378\n",
      "Epoch 26/40\n",
      "4s - loss: 0.5895 - acc: 0.7391\n",
      "Epoch 27/40\n",
      "4s - loss: 0.5893 - acc: 0.7394\n",
      "Epoch 28/40\n",
      "4s - loss: 0.5886 - acc: 0.7376\n",
      "Epoch 29/40\n",
      "4s - loss: 0.5856 - acc: 0.7408\n",
      "Epoch 30/40\n",
      "4s - loss: 0.5869 - acc: 0.7420\n",
      "Epoch 31/40\n",
      "4s - loss: 0.5853 - acc: 0.7401\n",
      "Epoch 32/40\n",
      "5s - loss: 0.5868 - acc: 0.7398\n",
      "Epoch 33/40\n",
      "4s - loss: 0.5832 - acc: 0.7413\n",
      "Epoch 34/40\n",
      "4s - loss: 0.5830 - acc: 0.7423\n",
      "Epoch 35/40\n",
      "4s - loss: 0.5838 - acc: 0.7416\n",
      "Epoch 36/40\n",
      "4s - loss: 0.5827 - acc: 0.7411\n",
      "Epoch 37/40\n",
      "4s - loss: 0.5815 - acc: 0.7415\n",
      "Epoch 38/40\n",
      "4s - loss: 0.5806 - acc: 0.7438\n",
      "Epoch 39/40\n",
      "5s - loss: 0.5810 - acc: 0.7420\n",
      "Epoch 40/40\n",
      "4s - loss: 0.5787 - acc: 0.7434\n",
      "9056/9871 [==========================>...] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 3 turn is:\n",
      "0.575131170675\n",
      "Epoch 1/40\n",
      "4s - loss: 0.7027 - acc: 0.7002\n",
      "Epoch 2/40\n",
      "4s - loss: 0.6366 - acc: 0.7145\n",
      "Epoch 3/40\n",
      "4s - loss: 0.6272 - acc: 0.7184\n",
      "Epoch 4/40\n",
      "4s - loss: 0.6203 - acc: 0.7237\n",
      "Epoch 5/40\n",
      "4s - loss: 0.6184 - acc: 0.7240\n",
      "Epoch 6/40\n",
      "4s - loss: 0.6133 - acc: 0.7261\n",
      "Epoch 7/40\n",
      "4s - loss: 0.6112 - acc: 0.7288\n",
      "Epoch 8/40\n",
      "4s - loss: 0.6080 - acc: 0.7280\n",
      "Epoch 9/40\n",
      "4s - loss: 0.6071 - acc: 0.7300\n",
      "Epoch 10/40\n",
      "4s - loss: 0.6052 - acc: 0.7313\n",
      "Epoch 11/40\n",
      "4s - loss: 0.6030 - acc: 0.7313\n",
      "Epoch 12/40\n",
      "5s - loss: 0.6021 - acc: 0.7298\n",
      "Epoch 13/40\n",
      "4s - loss: 0.6000 - acc: 0.7349\n",
      "Epoch 14/40\n",
      "3s - loss: 0.6011 - acc: 0.7346\n",
      "Epoch 15/40\n",
      "5s - loss: 0.5973 - acc: 0.7354\n",
      "Epoch 16/40\n",
      "4s - loss: 0.5957 - acc: 0.7360\n",
      "Epoch 17/40\n",
      "4s - loss: 0.5955 - acc: 0.7355\n",
      "Epoch 18/40\n",
      "5s - loss: 0.5951 - acc: 0.7355\n",
      "Epoch 19/40\n",
      "4s - loss: 0.5946 - acc: 0.7348\n",
      "Epoch 20/40\n",
      "4s - loss: 0.5927 - acc: 0.7365\n",
      "Epoch 21/40\n",
      "4s - loss: 0.5921 - acc: 0.7381\n",
      "Epoch 22/40\n",
      "4s - loss: 0.5901 - acc: 0.7392\n",
      "Epoch 23/40\n",
      "4s - loss: 0.5903 - acc: 0.7374\n",
      "Epoch 24/40\n",
      "4s - loss: 0.5881 - acc: 0.7388\n",
      "Epoch 25/40\n",
      "4s - loss: 0.5894 - acc: 0.7374\n",
      "Epoch 26/40\n",
      "4s - loss: 0.5874 - acc: 0.7393\n",
      "Epoch 27/40\n",
      "4s - loss: 0.5875 - acc: 0.7378\n",
      "Epoch 28/40\n",
      "4s - loss: 0.5868 - acc: 0.7383\n",
      "Epoch 29/40\n",
      "4s - loss: 0.5849 - acc: 0.7398\n",
      "Epoch 30/40\n",
      "4s - loss: 0.5871 - acc: 0.7395\n",
      "Epoch 31/40\n",
      "4s - loss: 0.5843 - acc: 0.7410\n",
      "Epoch 32/40\n",
      "4s - loss: 0.5822 - acc: 0.7424\n",
      "Epoch 33/40\n",
      "5s - loss: 0.5834 - acc: 0.7409\n",
      "Epoch 34/40\n",
      "4s - loss: 0.5834 - acc: 0.7393\n",
      "Epoch 35/40\n",
      "4s - loss: 0.5801 - acc: 0.7410\n",
      "Epoch 36/40\n",
      "4s - loss: 0.5826 - acc: 0.7400\n",
      "Epoch 37/40\n",
      "4s - loss: 0.5821 - acc: 0.7431\n",
      "Epoch 38/40\n",
      "4s - loss: 0.5824 - acc: 0.7397\n",
      "Epoch 39/40\n",
      "4s - loss: 0.5814 - acc: 0.7432\n",
      "Epoch 40/40\n",
      "5s - loss: 0.5797 - acc: 0.7420\n",
      "9792/9871 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 4 turn is:\n",
      "0.57296493361\n",
      "Epoch 1/40\n",
      "4s - loss: 0.7066 - acc: 0.6974\n",
      "Epoch 2/40\n",
      "4s - loss: 0.6391 - acc: 0.7149\n",
      "Epoch 3/40\n",
      "4s - loss: 0.6274 - acc: 0.7195\n",
      "Epoch 4/40\n",
      "4s - loss: 0.6219 - acc: 0.7223\n",
      "Epoch 5/40\n",
      "4s - loss: 0.6177 - acc: 0.7241\n",
      "Epoch 6/40\n",
      "4s - loss: 0.6148 - acc: 0.7254\n",
      "Epoch 7/40\n",
      "4s - loss: 0.6126 - acc: 0.7268\n",
      "Epoch 8/40\n",
      "4s - loss: 0.6109 - acc: 0.7275\n",
      "Epoch 9/40\n",
      "4s - loss: 0.6093 - acc: 0.7295\n",
      "Epoch 10/40\n",
      "4s - loss: 0.6079 - acc: 0.7288\n",
      "Epoch 11/40\n",
      "4s - loss: 0.6055 - acc: 0.7325\n",
      "Epoch 12/40\n",
      "5s - loss: 0.6040 - acc: 0.7309\n",
      "Epoch 13/40\n",
      "4s - loss: 0.6022 - acc: 0.7327\n",
      "Epoch 14/40\n",
      "4s - loss: 0.6024 - acc: 0.7316\n",
      "Epoch 15/40\n",
      "4s - loss: 0.5997 - acc: 0.7345\n",
      "Epoch 16/40\n",
      "4s - loss: 0.5992 - acc: 0.7329\n",
      "Epoch 17/40\n",
      "4s - loss: 0.5976 - acc: 0.7351\n",
      "Epoch 18/40\n",
      "4s - loss: 0.5969 - acc: 0.7327\n",
      "Epoch 19/40\n",
      "4s - loss: 0.5949 - acc: 0.7357\n",
      "Epoch 20/40\n",
      "4s - loss: 0.5953 - acc: 0.7359\n",
      "Epoch 21/40\n",
      "4s - loss: 0.5945 - acc: 0.7356\n",
      "Epoch 22/40\n",
      "4s - loss: 0.5940 - acc: 0.7361\n",
      "Epoch 23/40\n",
      "4s - loss: 0.5919 - acc: 0.7387\n",
      "Epoch 24/40\n",
      "4s - loss: 0.5912 - acc: 0.7374\n",
      "Epoch 25/40\n",
      "4s - loss: 0.5893 - acc: 0.7374\n",
      "Epoch 26/40\n",
      "4s - loss: 0.5914 - acc: 0.7370\n",
      "Epoch 27/40\n",
      "4s - loss: 0.5904 - acc: 0.7395\n",
      "Epoch 28/40\n",
      "4s - loss: 0.5894 - acc: 0.7391\n",
      "Epoch 29/40\n",
      "4s - loss: 0.5888 - acc: 0.7388\n",
      "Epoch 30/40\n",
      "4s - loss: 0.5872 - acc: 0.7382\n",
      "Epoch 31/40\n",
      "4s - loss: 0.5868 - acc: 0.7396\n",
      "Epoch 32/40\n",
      "4s - loss: 0.5871 - acc: 0.7382\n",
      "Epoch 33/40\n",
      "4s - loss: 0.5875 - acc: 0.7396\n",
      "Epoch 34/40\n",
      "4s - loss: 0.5851 - acc: 0.7404\n",
      "Epoch 35/40\n",
      "4s - loss: 0.5856 - acc: 0.7415\n",
      "Epoch 36/40\n",
      "4s - loss: 0.5835 - acc: 0.7393\n",
      "Epoch 37/40\n",
      "4s - loss: 0.5839 - acc: 0.7408\n",
      "Epoch 38/40\n",
      "3s - loss: 0.5830 - acc: 0.7423\n",
      "Epoch 39/40\n",
      "4s - loss: 0.5814 - acc: 0.7415\n",
      "Epoch 40/40\n",
      "4s - loss: 0.5829 - acc: 0.7408\n",
      "9440/9868 [===========================>..] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bthe cv_score for the 5 turn is:\n",
      "0.56641298967\n",
      "0.572584069936\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [64]:\n",
    "\n",
    "    i=0\n",
    "    cv_scores=[]\n",
    "    cv_result=[]\n",
    "    for dev_index, val_index in KF:\n",
    "        dev_set, val_set = train_df.iloc[dev_index,:] , train_df.iloc[val_index,:] \n",
    "        dev_X, val_X = dev_set[features].as_matrix(), val_set[features].as_matrix()\n",
    "        dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "        seed = 0\n",
    "        np.random.seed(seed)\n",
    "        model = nn_model(features,lr=0.1)\n",
    "        history=model.fit(dev_X, dev_y, epochs = 40, batch_size=batch_size, verbose = 2 \n",
    "          #,validation_data=[val_X, val_y], callbacks=[early_stopping]\n",
    "                         )\n",
    "        preds =  model.predict_proba(val_X)\n",
    "    \n",
    "            #save the pickles for futures use\n",
    "        pickl_file = store+'nn-5fold-out-'+str(i)+'.pickle'\n",
    "        fileObject = open(pickl_file,'wb') \n",
    "        pickle.dump(preds,fileObject)   \n",
    "        fileObject.close()    \n",
    "        \n",
    "        lls=log_loss(val_y, preds)\n",
    "        cv_scores.append(lls)\n",
    "        cv_result.append(history)\n",
    "        i+=1\n",
    "        print 'the cv_score for the '+str(i)+' turn is:'\n",
    "        print(lls)\n",
    "    \n",
    "    print np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "6s - loss: 0.6994 - acc: 0.7010\n",
      "Epoch 2/40\n",
      "4s - loss: 0.6329 - acc: 0.7182\n",
      "Epoch 3/40\n",
      "4s - loss: 0.6251 - acc: 0.7214\n",
      "Epoch 4/40\n",
      "5s - loss: 0.6190 - acc: 0.7238\n",
      "Epoch 5/40\n",
      "5s - loss: 0.6163 - acc: 0.7250\n",
      "Epoch 6/40\n",
      "5s - loss: 0.6110 - acc: 0.7278\n",
      "Epoch 7/40\n",
      "6s - loss: 0.6092 - acc: 0.7299\n",
      "Epoch 8/40\n",
      "5s - loss: 0.6060 - acc: 0.7316\n",
      "Epoch 9/40\n",
      "5s - loss: 0.6043 - acc: 0.7299\n",
      "Epoch 10/40\n",
      "6s - loss: 0.6025 - acc: 0.7335\n",
      "Epoch 11/40\n",
      "5s - loss: 0.6008 - acc: 0.7334\n",
      "Epoch 12/40\n",
      "5s - loss: 0.6003 - acc: 0.7347\n",
      "Epoch 13/40\n",
      "6s - loss: 0.5980 - acc: 0.7353\n",
      "Epoch 14/40\n",
      "5s - loss: 0.5962 - acc: 0.7374\n",
      "Epoch 15/40\n",
      "6s - loss: 0.5956 - acc: 0.7367\n",
      "Epoch 16/40\n",
      "5s - loss: 0.5949 - acc: 0.7358\n",
      "Epoch 17/40\n",
      "5s - loss: 0.5936 - acc: 0.7355\n",
      "Epoch 18/40\n",
      "6s - loss: 0.5933 - acc: 0.7376\n",
      "Epoch 19/40\n",
      "5s - loss: 0.5932 - acc: 0.7372\n",
      "Epoch 20/40\n",
      "5s - loss: 0.5905 - acc: 0.7385\n",
      "Epoch 21/40\n",
      "5s - loss: 0.5895 - acc: 0.7393\n",
      "Epoch 22/40\n",
      "5s - loss: 0.5905 - acc: 0.7377\n",
      "Epoch 23/40\n",
      "5s - loss: 0.5879 - acc: 0.7375\n",
      "Epoch 24/40\n",
      "5s - loss: 0.5867 - acc: 0.7378\n",
      "Epoch 25/40\n",
      "5s - loss: 0.5868 - acc: 0.7399\n",
      "Epoch 26/40\n",
      "5s - loss: 0.5865 - acc: 0.7402\n",
      "Epoch 27/40\n",
      "5s - loss: 0.5854 - acc: 0.7373\n",
      "Epoch 28/40\n",
      "6s - loss: 0.5856 - acc: 0.7404\n",
      "Epoch 29/40\n",
      "5s - loss: 0.5849 - acc: 0.7419\n",
      "Epoch 30/40\n",
      "5s - loss: 0.5828 - acc: 0.7406\n",
      "Epoch 31/40\n",
      "5s - loss: 0.5826 - acc: 0.7423\n",
      "Epoch 32/40\n",
      "6s - loss: 0.5817 - acc: 0.7419\n",
      "Epoch 33/40\n",
      "5s - loss: 0.5823 - acc: 0.7414\n",
      "Epoch 34/40\n",
      "5s - loss: 0.5812 - acc: 0.7412\n",
      "Epoch 35/40\n",
      "5s - loss: 0.5816 - acc: 0.7431\n",
      "Epoch 36/40\n",
      "5s - loss: 0.5784 - acc: 0.7420\n",
      "Epoch 37/40\n",
      "5s - loss: 0.5801 - acc: 0.7429\n",
      "Epoch 38/40\n",
      "5s - loss: 0.5804 - acc: 0.7428\n",
      "Epoch 39/40\n",
      "5s - loss: 0.5787 - acc: 0.7431\n",
      "Epoch 40/40\n",
      "5s - loss: 0.5793 - acc: 0.7439\n",
      "73536/74659 [============================>.] - ETA: 0s \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "\"\"\"trainX testX for et and rf \"\"\"\n",
    "train_X, test_X = train_df[features].as_matrix(), test_df[features].as_matrix()\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "model = nn_model(features,lr=0.1)\n",
    "history=model.fit(train_X, train_y, epochs = 40, batch_size=64, verbose = 2) \n",
    "  #,validation_data=[val_X, val_y])#, callbacks=[early_stopping])\n",
    "\n",
    "preds =  model.predict_proba(test_X)\n",
    "\n",
    "out_df = pd.DataFrame(preds)\n",
    "out_df.columns = [\"high\", \"medium\", \"low\"]\n",
    "out_df[\"listing_id\"] = test_df.listing_id.values\n",
    "out_df.to_json(store+'nn-bulk-out.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
